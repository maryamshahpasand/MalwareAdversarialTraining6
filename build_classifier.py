from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn import linear_model, svm, tree
from sklearn.metrics import confusion_matrix
import numpy as np
import pickle
import pathlib as Path
import os.path
from timeit import default_timer as timer
import scipy.sparse
from sklearn.model_selection import GridSearchCV
import torch.nn as nn
import torch.nn.functional as F
import torch
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.svm import LinearSVC , NuSVC
import matplotlib.pyplot as plt
from sklearn import preprocessing


def build_classifier(type='RF', data=[], train=True , por= '_0.5'):
    if type is 'RF':
        model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)
    elif type is 'SVM':
        # model = svm.SVC()
        # model = svm.SVC(kernel='linear', class_weight={1: 9})

        Parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}
        model = GridSearchCV(LinearSVC(), Parameters, cv=5, scoring='f1', n_jobs=-1)
    elif type is 'RBF_SVM':
        # Parameters={'kernel':['rbf'],'gamma': [1e-3, 1e-4],'C': [0.001, 0.01, 0.1]}
        # model = GridSearchCV(svm.SVC(), Parameters, cv=5, scoring='f1', n_jobs=-1)
        model=svm.SVC(kernel='rbf')
    elif type is 'LR':
        model = linear_model.LogisticRegression()
    elif type is 'DT':
        model = tree.DecisionTreeRegressor()
    elif type is 'KNN':
        model = KNeighborsClassifier()
    elif type is 'MLP':
        model = MLPClassifier(hidden_layer_sizes=(1000,), max_iter=200, alpha=1e-4,
                              solver='sgd', verbose=0, tol=1e-4, random_state=1,
                              learning_rate_init=.1)

    if train:
        (xmal, ymal), (xben, yben), (xtsmal, xtsben), (ytsmal, ytsben) = data[0], data[1], data[2], data[3]
        # xtrain = scipy.sparse.vstack((xben, xmal))
        # ytrain = np.concatenate([yben, ymal])
        # xtest = scipy.sparse.vstack((xtsmal, xtsben))
        # ytest = np.concatenate([ytsmal, ytsben])
        xtrain = np.concatenate([xben, xmal])
        ytrain = np.concatenate([yben, ymal])
        xtest = np.concatenate([xtsmal, xtsben])
        ytest = np.concatenate([ytsmal, ytsben])

        print('\n\n--- Round: {0} '.format(0))

        print('=============data============= ')
        print(
            'number of original malware = {0}\n'
            'number of adversarial samples (old+new) = {1}\n'
            'number of new adversarial samples = {2}\n'
            'Malware to benign Ratio: {3:.2f}\n'
            'adversarial samples portion of malware samples = {4:.2f}\n'
            'adversarial samples portion of all samples = {5:.2f} '
                # .format(len(xmal) + len(data[2][0][(data[2][1]==1).nonzero()[0]]),a
                .format(xmal.shape[0],
                        0,
                        0,
                        xmal.shape[0] / xben.shape[0],
                        0,
                        0
                        ))
        print('==============================\n ')

        print('TRAINING CLASSIFIER...\n')
        start_train = timer()
        model.fit(xtrain, ytrain)

        # Parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}
        #
        # Clf = GridSearchCV(LinearSVC(), Parameters, cv=5, scoring='f1', n_jobs=-1)
        # SVMModels = Clf.fit(xtrain, ytrain)
        #
        # BestModel = SVMModels.best_estimator_
        # print("Best Model Selected : {}".format(BestModel))
        # # print("The training time for random split classification is %s sec." % (round(time.time() - T0, 2)))
        # print("Enter a filename to save the model:")
        # # filename = raw_input()
        # filename = "SVM"
        #
        # # step 4: Evaluate the best model on test set
        # y_pred = SVMModels.predict(xtest)
        # # print("The testing time for random split classification is %s sec." % (round(time.time() - T0, 2)))
        # Accuracy = accuracy_score(ytest, y_pred)
        # print("Test Set Accuracy = {}".format(Accuracy))
        # print(metrics.classification_report(ytest,
        #                                     y_pred, labels=[1, 0],
        #                                     target_names=['Malware', 'Goodware']))

        if os.path.isfile('./models/'+type+'__'+por+'.sav'):
        # if os.path.isfile('/home/maryam/Code/python/adversarial_training/torch_impl/Different_ratio/models/'+type+'weighted__'+por+'.sav'):
            model = pickle.load(open('./models/'+type+'__'+por+'.sav', 'rb'))
                    # '/home/maryam/Code/python/adversarial_training/torch_impl/Different_ratio/models/'+type+'weighted__'+por+'.sav', 'rb'))
        else:
            model.fit(xtrain, ytrain)
            pickle.dump(model, open('./models/'+type+'__'+por+'.sav', 'wb'))
            # pickle.dump(model, open('/home/maryam/Code/python/adversarial_training/torch_impl/Different_ratio/models/'+type+'weighted__'+por+'.sav', 'wb'))

        end_train = timer()

        print('training completed in %.3f seconds:' % (end_train - start_train))
        print('=============results ============= ')

        # conf_matx = confusion_matrix(ytrain, model.predict(xtrain))
        # print("Test Set Accuracy = {}".format(accuracy_score(ytest, model.predict(xtest))))
        # print('Train Confusion :: TN: {0}  FP: {1}  FN: {2}  TP: {3}'.format(conf_matx[0][0], conf_matx[0][1],
        #                                                                      conf_matx[1][0],
        #                                                                      conf_matx[1][1]))
        # train_FNR = conf_matx[1][0] / (conf_matx[1][0] + conf_matx[1][1])
        # y_pred=model.predict(xtest)
        # conf_matx = confusion_matrix(ytest,y_pred )
        # print('Test  Confusion :: TN: {0}  FP: {1}  FN: {2}  TP: {3} '.format(conf_matx[0][0],
        #                                                                       conf_matx[0][1],
        #                                                                       conf_matx[1][0],
        #                                                                       conf_matx[1][1]))
        # test_FNR = conf_matx[1][0] / (conf_matx[1][0] + conf_matx[1][1])
        # test_FPR = conf_matx[0][1] / (conf_matx[0][1] + conf_matx[0][0])
        #
        # Original_Train_TPR = model.score(xtrain, ytrain)
        # Original_Test_TPR = model.score(xtest, ytest)
        # print('Original_Train_TPR: {0}, Original_Test_TPR: {1} , FNR for train: {2} , FNR for test: {3}'.format(
        #     Original_Train_TPR, Original_Test_TPR, train_FNR, test_FNR))
        #
        # print(metrics.classification_report(ytest,y_pred, labels=[1, 0],target_names=['Malware', 'Goodware']))
        print('==============================\n ')

        # return model, [Original_Train_TPR, Original_Test_TPR, Original_Test_TPR, train_FNR, test_FNR, test_FNR,test_FPR,
        #                (end_train - start_train)]
        return model, [0, 0, 0, 0, 0, 0,0,
                       (end_train - start_train)]
        # return model, [ ]
    else:
        return model


class malware_classifier_net(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(malware_classifier_net, self).__init__()
        self.map1 = nn.Linear(input_size, hidden_size)
        self.map2 = nn.Linear(hidden_size, hidden_size)
        self.map3 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = F.elu(self.map1(x))
        x = F.elu(self.map2(x))
        # x= F.elu(self.map3(x))
        # x= torch.sigmoid(self.map3(x))
        return torch.softmax(self.map3(x), dim=1)
        # return torch.sigmoid(self.map3(x))


def train_target_model(malware_classifier_net, dataloader, epochs):
    criterian =  nn.BCELoss()
    loss=[]
    lb = preprocessing.LabelBinarizer()
    lb.fit([0,1])
    # malware_classifier_net.netClassifier = malware_classifier_net(1).to(device)
    optimizer_C = torch.optim.Adam(malware_classifier_net.parameters(), lr=2e-3 , betas=(0.99, 0.999))
    for epoch in range(epochs):
        for local_batch, local_lable in dataloader:
            malware_classifier_net.zero_grad()
            # pred_class = malware_classifier_net(torch.from_numpy(local_batch).float().cuda())
            pred_class = malware_classifier_net(local_batch.float().cuda())
            # local_lable[(torch.unsqueeze(local_lable, 1)[:, 0] == 0).nonzero()] = [1, 0]
            # local_lable[(torch.unsqueeze(local_lable, 1)[:, 0] == 1).nonzero()] = [0, 1]
            local_lable = np.hstack(( 1 - lb.transform(local_lable),lb.transform(local_lable)))
            loss_Classifier =criterian(pred_class,torch.from_numpy(local_lable).float().cuda() )
            # loss_Classifier =criterian(torch.max(pred_class , 1)[0],local_lable.float().cuda() )
            loss_Classifier.backward()
            optimizer_C.step()
        loss.append(loss_Classifier.cpu().detach().numpy())
        print(epoch , ":",loss_Classifier.cpu().detach().numpy() )
    # plt.plot(range(len(loss)), loss, label='lr:2e-3, bs=500')
    # plt.show()
    return  malware_classifier_net