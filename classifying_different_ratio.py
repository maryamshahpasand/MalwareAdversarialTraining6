import build_classifier
import load_data


import numpy as np
import sys
import psutil
import os
import csv
import random
from timeit import default_timer as timer

from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, \
    roc_auc_score

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torch.utils.data as data_utils

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn import linear_model, svm, tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import sklearn

import pickle



class Generator(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(Generator, self).__init__()
        self.map1 = nn.Linear(input_size, hidden_size)
        # self.map2 = nn.Linear(hidden_size, hidden_size)
        # self.map3 = nn.Linear(hidden_size, output_size)
        self.map2 = nn.Linear(hidden_size, output_size)

    def forward(self, x_and_example):
        x = torch.cat((x_and_example[0], x_and_example[1]), 1)
        x = F.sigmoid(self.map1(x))
        x = F.sigmoid(self.map2(x))
        # x = F.sigmoid(self.map3(x))

        return torch.max(x_and_example[0], x)


class Discriminator(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(Discriminator, self).__init__()
        self.map1 = nn.Linear(input_size, hidden_size)
        self.map2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = F.sigmoid(self.map1(x))
        return F.sigmoid(self.map2(x))


class GAN():
    def __init__(self, input_size, hidden_size, noise_size):
        self.otiginal_data_size = 0
        self.noise_size = noise_size
        self.gloss = []
        self.dloss = []
        self.criterion = nn.BCELoss()
        self.criterion_ = nn.L1Loss()
        self.D = Discriminator(input_size=input_size, hidden_size=hidden_size, output_size=1).cuda()
        self.d_optimizer = optim.Adam(self.D.parameters(), lr=0.001, betas=(0.9, 0.999))
        self.G = Generator(input_size=input_size + self.noise_size, hidden_size=hidden_size,
                           output_size=input_size).cuda()
        self.g_optimizer = optim.Adam(self.G.parameters(), lr=0.001, betas=(0.9, 0.999))


def test_classifier(classifier,data):


    (xmal, ymal), (xben, yben), (xtsmal, xtsben), (ytsmal, ytsben) = data[0], data[1], data[2], data[3]


    for i in range(10):

        print('Loading GAN model...\n')

        GAN_.G = torch.load('/home/maryam/Code/python/adversarial_training/torch_impl/Different_ratio/_0.5/malgan{0}.pt'.format(i))

        print('==============Results for loaded gan from round %d ============ \n' %i)

        print('\nGenerating Adversarial Examples from test set...')
        noise = np.random.uniform(0, 1, (xtsmal.shape[0], 20))

        with torch.no_grad():
            # not to generate adv version from other avd samples
            gen_examples = GAN_.G([torch.from_numpy(xtsmal).float().cuda(),
                                   torch.from_numpy(noise).float().cuda()]).detach()
        x_test_gen_examples = (np.ones(gen_examples.cpu().shape) * (gen_examples.cpu() > 0.5)).numpy()
        y_test_gen_examples = np.ones(len(gen_examples.cpu()))

        conf_matx = confusion_matrix(y_test_gen_examples,np.round(classifier.predict(x_test_gen_examples)))
        print('Clean Test  Confusion :: TN: {0}  FP: {1}  FN: {2}  TP: {3} '.format(conf_matx[0][0], conf_matx[0][1],
                                                                                    conf_matx[1][0],
                                                                                    conf_matx[1][1]))
        Clean_test_FNR = conf_matx[1][0] / (conf_matx[1][0] + conf_matx[1][1])

        print('\nGenerating  Adversarial Examples from train set...')
        noise = np.random.uniform(0, 1, (xmal.shape[0], 20))

        with torch.no_grad():
            # not to generate adv version from other avd samples
            gen_examples = GAN_.G([torch.from_numpy(xmal).float().cuda(),
                                   torch.from_numpy(noise).float().cuda()]).detach()
        x_train_gen_examples = (np.ones(gen_examples.cpu().shape) * (gen_examples.cpu() > 0.5)).numpy()
        y_train_gen_examples = np.ones(len(gen_examples.cpu()))

        conf_matx = confusion_matrix(y_train_gen_examples , np.round(classifier.predict(x_train_gen_examples) ))
        print('Clean Test  Confusion :: TN: {0}  FP: {1}  FN: {2}  TP: {3} '.format(conf_matx[0][0], conf_matx[0][1],
                                                                                    conf_matx[1][0],
                                                                                    conf_matx[1][1]))
        Clean_train_FNR = conf_matx[1][0] / (conf_matx[1][0] + conf_matx[1][1])
        print(
            'Clean_test_FNR: {0} \n Clean_train_FNR: {1}  '
                .format(Clean_test_FNR, Clean_train_FNR))
        print('==============================\n ')





    #
    # xtrain = np.concatenate([data[0][0], data[1][0]])
    # ytrain = np.concatenate([data[0][1], data[1][1]])
    # classifier.fit(xtrain,ytrain)
    # y_test = data[2][1]
    # ypred = classifier.predict(data[2][0])
    # print('Confusion for Train: \n' )
    # ypred_train = classifier.predict(xtrain)
    # conf_matx = confusion_matrix(ytrain, np.round(ypred_train))
    # print('TN: {0} \nFP: {1} \nFN: {2} \nTP: {3}\n'.format(conf_matx[0][0], conf_matx[0][1], conf_matx[1][0],
    #                                                        conf_matx[1][1]))
    # print('accuracy_score for Train: ',
    #       accuracy_score(ytrain, np.round(ypred_train)))
    # print('FNR for Train: ',
    #       conf_matx[1][0] /(conf_matx[1][0]+conf_matx[1][1]))
    # print('Confusion for Test: \n' )
    # conf_matx = confusion_matrix(y_test, np.round(ypred))
    # print('TN: {0} \nFP: {1} \nFN: {2} \nTP: {3}\n'.format(conf_matx[0][0], conf_matx[0][1], conf_matx[1][0],
    #                                                        conf_matx[1][1]))
    # print('roc_auc_score: ',
    #       roc_auc_score(y_test, np.round(ypred)))
    #
    # print('accuracy_score for Test: ',
    #       accuracy_score(y_test, np.round(ypred)))
    # print('FNR for Test: ',
    #       conf_matx[1][0] /(conf_matx[1][0]+conf_matx[1][1]))

def train_classifier(classifier,data):
    xtrain = np.concatenate([data[0][0], data[1][0]])
    ytrain = np.concatenate([data[0][1], data[1][1]])
    classifier.fit(xtrain,ytrain)
    pickle.dump(classifier , open('/home/maryam/Code/python/adversarial_training/torch_impl/Different_ratio/models/mari.sav' , 'wb'))
    # y_test = data[2][1]
    # ypred = classifier.predict(data[2][0])
    # print('Confusion for Train: \n' )
    # ypred_train = classifier.predict(xtrain)
    # conf_matx = confusion_matrix(ytrain, np.round(ypred_train))
    # print('TN: {0} \nFP: {1} \nFN: {2} \nTP: {3}\n'.format(conf_matx[0][0], conf_matx[0][1], conf_matx[1][0],
    #                                                        conf_matx[1][1]))
    # print('accuracy_score for Train: ',
    #       accuracy_score(ytrain, np.round(ypred_train)))
    # print('FNR for Train: ',
    #       conf_matx[1][0] /(conf_matx[1][0]+conf_matx[1][1]))
    # print('Confusion for Test: \n' )
    # conf_matx = confusion_matrix(y_test, np.round(ypred))
    # print('TN: {0} \nFP: {1} \nFN: {2} \nTP: {3}\n'.format(conf_matx[0][0], conf_matx[0][1], conf_matx[1][0],
    #                                                        conf_matx[1][1]))
    # print('roc_auc_score: ',
    #       roc_auc_score(y_test, np.round(ypred)))
    #
    # print('accuracy_score for Test: ',
    #       accuracy_score(y_test, np.round(ypred)))
    # print('FNR for Test: ',
    #       conf_matx[1][0] /(conf_matx[1][0]+conf_matx[1][1]))



if __name__ == '__main__':



    # results = []
    # xmal, ymal, xben, yben = load_data()
    (xmal, ymal), (xben, yben),(xtest_mal, xtest_ben), (ytest_mal, ytest_ben) = load_data()
    # data = load_data()
    GAN_ = GAN(input_size=xmal.shape[1], hidden_size=200, noise_size=20)

    classifiers = [  'DT' , 'MLP' , 'RBF_SVM'  , 'KNN']
    for por in [0.1 , 0.2 ,0.3 ,0.4 ,0.5]:
        porr = round((len(xmal)/0.4) -len(xmal))
        xtrain_mal, xtest_mal, ytrain_mal, ytest_mal = train_test_split(xmal, ymal, test_size=0.20)
        xtrain_ben, xtest_ben, ytrain_ben, ytest_ben = train_test_split(xben[0:porr], yben[0:porr], test_size=0.20)
        # xtrain_ben, xtest_ben, ytrain_ben, ytest_ben = train_test_split(xben, yben, test_size=0.20)
        print(
            # 'Malwar Ratio = {4}\n'
            'number of malware for training = {0}\n'
            'number of benign for training= {1}\n'
            'number of malware for test  = {2}\n'
            'number of benign for test= {3}\n'
                .format(len(xtrain_mal),
                        len(xtrain_ben),
                        len(xtest_mal),
                        # len(xtest_ben),por))
                        len(xtest_ben)))
        data = [(xtrain_mal, ytrain_mal), (xtrain_ben, ytrain_ben),
         # (np.concatenate([xtest_mal, xtest_ben]), np.concatenate([ytest_mal, ytest_ben]))]
         (xtest_mal, xtest_ben), (ytest_mal, ytest_ben)]
        for clasifier in classifiers:
            print("\n<<<<<<<<<EXPERIMENT ON " + clasifier + ">>>>>>>>>")
            # classifier_ = pickle.load(open('/home/maryam/Code/python/adversarial_training/torch_impl/Different_ratio/models/'+clasifier+'__'+str(por)+'.sav', 'rb'))

            classifier_ = build_classifier(type =clasifier)
            classifier_.fit(np.concatenate([xtrain_mal,xtrain_ben]) , np.concatenate([ytrain_mal, ytrain_ben]))
            pickle.dump(classifier_,
                        open('/home/maryam/Code/python/adversarial_training/torch_impl/Different_ratio/models/'+clasifier+'__'+str(por)+'.sav' ,
                             'wb'))

            classifier_ = pickle.load(open('/home/maryam/Code/python/adversarial_training/torch_impl/Different_ratio/models/'+clasifier+'__'+str(por)+'.sav', 'rb'))
            test_classifier(classifier_, data)
            # print(result)